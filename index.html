<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Language-Guided Preference Learning Enables generation of diverse expressive behaviors from a single policy.">
  <meta name="keywords" content="Preference Learning, Locomotion, Human-Robot Interaction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Language-Guided Preference Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://jadenvc.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://jadenvc.github.io">
            ILIAD
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Zero-shot Shark Tracking and Biometrics from Aerial Imagery</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Chinmay Lalgudi</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/mark-leone1/">Mark Leone</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://jadenvc.github.io">Jaden Clark</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/sergio-madrigal-mora-72a37319a/?locale=es_ES">Sergio Madrigal-Mora</a><sup>1</sup>
            </span>
            <span class="author-block">
              <a href="https://www.researchgate.net/profile/Mario-Espinoza-3">Mario Espinoza</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Stanford University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2502.03717"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2502.03717"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1GYp0oE8F0LaE9yVkFHPHEGQdHQ0dKgic/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">LGPL</span> generates accurate, expressive behaviors from a single task-conditioned policy.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Expressive robotic behavior is essential for the widespread acceptance of robots in social environments. Recent advancements in learned legged locomotion controllers have enabled more dynamic and versatile robot behaviors. However, determining the optimal behavior for interactions with different users across varied scenarios remains a challenge. Current methods either rely on natural language input, which is efficient but low-resolution, or learn from human preferences, which, although high-resolution, is sample inefficient. This paper introduces a novel approach that leverages priors generated by pre-trained LLMs alongside the precision of preference learning. Our method, termed Language-Guided Preference Learning (LGPL), uses LLMs to generate initial behavior samples, which are then refined through preference-based feedback to learn behaviors that closely align with human expectations. Our core insight is that LLMs can guide the sampling process for preference learning, leading to a substantial improvement in sample efficiency. We demonstrate that LGPL can quickly learn accurate and expressive behaviors with as few as four queries,  outperforming both purely language-parameterized models and traditional preference learning approaches.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/jkuhA4--F8w?si=CItyM_L5dtGQnKxO" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/excited.mov"
                    type="video/mp4">
          </video>
          <p class="video-title">"Act excited"</p>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/scare.mov"
                    type="video/mp4">
          </video>
          <p class="video-title">"Act scared"</p>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/happy.mov"
                    type="video/mp4">
          </video>
          <p class="video-title">"Act happy"</p>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/sad.mov"
                    type="video/mp4">
          </video>
          <p class="video-title">"Act sad"</p>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/angry.mov"
                    type="video/mp4">
          </video>
          <p class="video-title">"Act angry"</p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">LGPL</h2>
          <p>
            LGPL generates an accurate, human-aligned gait for the scared behavior. We found that LGPL tasks were preferred over competing methods 75.83 ± 5.14% of the time by users in a video survey.


          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/scared.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">L2R</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              After receiving semantic feedback, L2RF generates an innaccurate gait due to low-quality feedback from a non-expert user. One round of language feedback only improved behaviors 40 percent of the time.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/forward.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">User Studies</h2>

<!--         Interpolating. -->
<!--         <h3 class="title is-4">Adapation to feedback</h3>
        <div class="content has-text-justified">
          <p>
            LGPL generates more accurate behaviors in response to feedback.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <h3 class="title is-4">Results</h3>
        <div class="content has-text-justified">
          <p>
            We found that LGPL was preferred 76.67 ± 10.59% of the compared to baseline methods in an active user study.
          </p>
        </div>
        <div class="content has-text-centered">
          <!-- Display the first image (results.jpg) -->
          <img id="results-image"
               src="./static/images/results.jpg"
               alt="Results"
               style="width: 75%; margin-bottom: 20px;">
          
          <!-- Display the second image (table.jpg) -->
          <img id="table-image"
               src="./static/images/table.jpg"
               alt="Table"
               style="width: 75%;">
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Prompting</h2>

        <div class="content has-text-justified">
          <p>
            You are a dog foot contact pattern expert.
            Your job is to give a velocity, pitch, and a foot contact pattern based on the input.
            You will always give the output in the correct format no matter what the input is.
            <Gait definition block>
            The following are description about gaits:
            
            1. Trotting is a gait where two diagonally opposite legs strike the ground at the same time.
            2. Pacing is a gait where the two legs on the left/right side of the body strike the ground at
            the same time. This gate is smoother and more controlled
            3. Bounding is a gait where the two front/rear legs strike the ground at the same time.
            It has a longer suspension phase where all feet are off the ground, for example,
            for at least 25% of the cycle length. This gait is particularly emotive.
            <Output format definition block>
            The following are rules for describing the velocity, pitch, and foot contact patterns:
            4. You should first output the velocity, then the foot contact pattern. If necessary, also output a pitch pattern
            5. There are 5 pitch to choose from: [-0.3, -0.15, 0.0, 0.15, 0.3]
            6. There are five velocities to choose from: [-0.5, -0.25, 0.0, 0.25, 0.5].
            7. A pattern is either bound, trot, or pace. Bound is [0,1,0] trot is [0,0,1] and pace is [1,0,0]
            <Examples block>
            Input: Trot slowly
            Output: 0.25
            Gait: [1,0,0]
            Pitch:0
            Input: Bound in place
            Output: 0.0
            Gait: [0,1,0]
            Pitch: 0
            Input: Pace backward fast
            Output: -0.5
            Gait: [1,0,0]
            Pitch:0.0
            Input: Walk forward and look up
            Output: 0.5
            Gait: [1,0,0]
            Pitch: 0.3
            Please generate 4 gaits covering all possible behaviors for a happy dog
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            More about Pupper via <a href="https://cs123-stanford-2024.readthedocs.io/en/latest/">CS 123 </a>.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{clark2024lgpl,
  author    = {Clark, Jaden and Hejna, Joey and Sadigh, Dorsa},
  title     = {Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning},
  journal   = {preprint},
  year      = {2024},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This website template was borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
